{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading of the emails (enron)\n",
    "emailspam=[]\n",
    "directory=\"data/spam\"\n",
    "for file in sorted(os.listdir(directory)):\n",
    "    f=open(directory+\"/\"+file,\"r\",encoding='cp437')\n",
    "    b=f.readline().lower()\n",
    "    b=b.replace(\"subject: fw :\",\"\")\n",
    "    b=b.replace(\"subject: fw : fw :\",\"\")\n",
    "    b=b.replace(\"subject: re : re :\",\"\")\n",
    "    b=b.replace(\"subject: re :\",\"\")\n",
    "    b=b.replace(\"subject: \",\"\")\n",
    "    a=b+f.read().lower()\n",
    "    emailspam.append(a)\n",
    "    \n",
    "emailham=[]\n",
    "directory=\"data/ham\"\n",
    "for file in sorted(os.listdir(directory)):\n",
    "    f=open(directory+\"/\"+file,\"r\",encoding='cp437')\n",
    "    a=f.readline().lower()\n",
    "    start=1\n",
    "    b=\"\"\n",
    "    while a!=\"\":\n",
    "        if start==1:\n",
    "            b+=a\n",
    "            a=f.readline()\n",
    "        else:\n",
    "            a=f.readline()\n",
    "            \n",
    "        if a[:7]==\"subject\":\n",
    "            start=1\n",
    "        elif a[:10]==\"- - - - - \" or a==\"\":\n",
    "            start=0\n",
    "            emailham.append(b)\n",
    "            b=\"\"\n",
    "\n",
    "            \n",
    "for i in range(len(emailham)):\n",
    "    b=emailham[i]\n",
    "    b=b.replace(\"subject: fw :\",\"\")\n",
    "    b=b.replace(\"subject: fw : fw :\",\"\")\n",
    "    b=b.replace(\"subject: re : re :\",\"\")\n",
    "    b=b.replace(\"subject: re :\",\"\")\n",
    "    b=b.replace(\"subject: \",\"\")\n",
    "    emailham[i]=b\n",
    "    \n",
    "s_len=len(emailspam)\n",
    "h_len=len(emailham)\n",
    "emails=emailspam+emailham\n",
    "labels=np.hstack(((np.ones(s_len),np.zeros(h_len))))\n",
    "emails=np.vstack((np.array(emails).transpose(),labels)).transpose()          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbol_color_removal(email):\n",
    "    e_mod=email\n",
    "    sym=[\"\\\\\",\"&\",\"!\",\".\",\",\",\"/\",\"+\",\"*\",\"%\",\"(\",\")\",\":\",\";\",\"\\\"\",\"_\",\"?\",\"=\",\"@\",\"{\",\"}\",\"[\",\"]\",\"<\",\">\",\"|\"]\n",
    "    f=open(\"data/color_codes.txt\",\"r\")\n",
    "    color=f.read().split(\"\\n\")\n",
    "    for s in sym:\n",
    "        e_mod=e_mod.replace(s,\" \")\n",
    "    e_mod=e_mod.replace(\"\\'\",\"\")\n",
    "    e_mod=e_mod.replace(\"\\n\",\" \")\n",
    "    e_mod=e_mod.replace(\"-\",\"\")\n",
    "    for c in color:\n",
    "        e_mod=e_mod.replace(c,\"\")\n",
    "\n",
    "    return e_mod\n",
    "\n",
    "def lemmatisation(email,dic):\n",
    "    \n",
    "    for key in dic.keys():\n",
    "        e_mod=email.replace(key,\" \"+dic[key]+\" \")\n",
    "    \n",
    "    return e_mod\n",
    "\n",
    "\n",
    "def num_token(email):\n",
    "    num=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n",
    "    e_mod=email\n",
    "    for n in num:\n",
    "        e_mod=e_mod.replace(n,\" \")\n",
    "    \n",
    "    return e_mod\n",
    "\n",
    "def stop_words():\n",
    "    f=open(\"data/stop_words.txt\",\"r\")\n",
    "    stop_words=f.read().split(\"\\n\")\n",
    "\n",
    "    return stop_words\n",
    "\n",
    "def html_words():\n",
    "    f=open(\"data/html_words.txt\",\"r\")\n",
    "    h_words=f.read().split(\"\\n\")\n",
    "\n",
    "    return h_words\n",
    "\n",
    "def rtf_words():\n",
    "    f=open(\"data/rtf_words.txt\",\"r\")\n",
    "    r_words=f.read().split(\"\\n\")\n",
    "\n",
    "    return r_words\n",
    "\n",
    "def idf(bag,lis):\n",
    "    idf_list=[]\n",
    "    N=len(lis)\n",
    "    for term in bag:\n",
    "        a=0\n",
    "        for doc in lis:\n",
    "            if term in doc:\n",
    "                a+=1\n",
    "        if a==0:\n",
    "            a=N\n",
    "        idf_list.append(a)\n",
    "    idf_vector=np.log(N/np.array(idf_list,dtype=\"float64\"))\n",
    "    return idf_vector\n",
    "\n",
    "def tf(bag,doc):\n",
    "    N=len(bag)\n",
    "    tf_list=[]\n",
    "    for i in range(N):\n",
    "        count=doc.count(bag[i])\n",
    "        tf_list.append(count/len(doc))\n",
    "    tf_vector=np.array(tf_list,dtype=\"float64\")\n",
    "    return tf_vector\n",
    "\n",
    "def tf_idf_vectorisation(bag,emails):\n",
    "    idf_v=idf(bag,emails)\n",
    "    N=len(bag)\n",
    "    num_of_docs=len(emails)\n",
    "    X=np.empty((N,num_of_docs))\n",
    "    for i in range(num_of_docs):\n",
    "        tf_v=tf(bag,emails[i])\n",
    "        X[:,i]=tf_v*idf_v\n",
    "    \n",
    "    return X\n",
    "\n",
    "def smote(X,N,k=5):\n",
    "    X_mod=X.transpose()\n",
    "    for i in range(X.shape[1]):\n",
    "        current=X[:,i]\n",
    "        dist=np.linalg.norm(X.transpose()-X[:,i],axis=1)\n",
    "        dist_list=dist.tolist()\n",
    "        neighbours=[]\n",
    "        for j in range(k):\n",
    "            min_pos=dist_list.index(min(dist_list))\n",
    "            neighbours.append(X[:,min_pos])\n",
    "            dist_list[min_pos]=max(dist_list)+1000\n",
    "\n",
    "        a=np.arange(k)\n",
    "        np.random.shuffle(a)\n",
    "        neighbours_array=(np.array(neighbours))[a[:N]]\n",
    "        c=np.random.uniform(0.0001,1,N)\n",
    "        new_x=current+(c*(neighbours_array-current).transpose()).transpose()\n",
    "        X_mod=np.vstack((X_mod,new_x))\n",
    "        \n",
    "    return (X_mod.transpose())\n",
    "\n",
    "def split(emails,h_len,s_len):\n",
    "\n",
    "\n",
    "    emails_spam=emails[:s_len]\n",
    "    emails_ham=emails[s_len:]\n",
    "    \n",
    "    np.random.shuffle(emails_spam)\n",
    "    np.random.shuffle(emails_ham)\n",
    "    \n",
    "    emails_spam_train=emails_spam[:int(0.7*s_len)]\n",
    "    emails_ham_train=emails_ham[:int(0.7*h_len)]\n",
    "    \n",
    "    emails_spam_test=emails_spam[int(0.7*s_len):]\n",
    "    emails_ham_test=emails_ham[int(0.7*h_len):]\n",
    "    \n",
    "    emails_train=emails_spam_train+emails_ham_train\n",
    "    emails_test=emails_spam_test+emails_ham_test\n",
    "    label_train=np.hstack((np.ones(len(emails_spam_train)),np.zeros(len(emails_ham_train))))\n",
    "    label_test=np.hstack((np.ones(len(emails_spam_test)),np.zeros(len(emails_ham_test))))\n",
    "    \n",
    "    return emails_train,emails_test,label_train,label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_dictionary=np.load(\"lemma_dictionary.npy\",allow_pickle=True).tolist()\n",
    "for i in range(len(emails)):\n",
    "    emails[i,0]=symbol_color_removal(emails[i,0])\n",
    "    emails[i,0]=num_token(emails[i,0])\n",
    "    emails[i,0]=lemmatisation(emails[i,0],lemma_dictionary)\n",
    "    \n",
    "s_words=stop_words()\n",
    "h_words=html_words()\n",
    "r_words=rtf_words()\n",
    "length=len(emails)\n",
    "emails_list=[]\n",
    "emails_list_labels=[]\n",
    "for i in range(length):\n",
    "    e=emails[i,0].strip().split(\" \")\n",
    "    l=[x for x in e if x not in s_words and  x not in h_words and x not in r_words and x!=\" \" and x!=\"\" and x!=\"#\"]\n",
    "    if l!=[]:\n",
    "        emails_list.append(l)\n",
    "        emails_list_labels.append(emails[i,1])\n",
    "\n",
    "spam_len=list(map(float,emails_list_labels)).index(0.0)\n",
    "ham_len=len(emails_list_labels)-spam_len\n",
    "\n",
    "email_train,email_test,label_train,label_test=split(emails_list,ham_len,spam_len)\n",
    "\n",
    "emails_train_flat=[i for j in email_train for i in j]\n",
    "emails_bag=list(set(emails_train_flat))\n",
    "\n",
    "\n",
    "X_train_nolabel=tf_idf_vectorisation(emails_bag,email_train)\n",
    "\n",
    "X_test=tf_idf_vectorisation(emails_bag,email_test).transpose()\n",
    "\n",
    "no_of_spams=(label_train.tolist()).index(0.0)\n",
    "no_of_hams=len(label_train)-no_of_spams\n",
    "rate=int(no_of_hams/no_of_spams) -1\n",
    "\n",
    "spam_balanced=smote(X_train_nolabel[:,:no_of_spams],rate)\n",
    "\n",
    "X_train=np.vstack((spam_balanced.transpose(),X_train_nolabel[:,no_of_spams:].transpose()))\n",
    "spam_count_balanced=spam_balanced.shape[1]\n",
    "y_train=np.hstack((np.ones(spam_count_balanced),np.zeros(no_of_hams)))\n",
    "\n",
    "lsvc=svm.LinearSVC(C=10,max_iter=10000)\n",
    "lsvc.fit(X_train,y_train)\n",
    "y_pred=lsvc.predict(X_test)\n",
    "accuracy=np.sum(1-np.abs(y_pred-label_test))/len(label_test)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
